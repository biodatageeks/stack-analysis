2021-06-04 17:02:44,665 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:02:45,603 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 17:03:23,102 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 17:03:23,103 - kedro.pipeline.node - INFO - Running node: split_data([input_data,params:example_test_data_ratio]) -> [testing_data,training_data]
2021-06-04 17:03:23,168 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 17:03:23,169 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 17:03:23,170 - kedro.runner.sequential_runner - INFO - Completed 1 out of 2 tasks
2021-06-04 17:03:23,170 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 17:03:23,171 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 17:03:31,864 - kedro_pyspark.pipelines.data_science.nodes - INFO - Training data count: 51743
2021-06-04 17:03:31,865 - kedro.runner.sequential_runner - INFO - Completed 2 out of 2 tasks
2021-06-04 17:03:31,866 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-06-04 17:03:31,867 - kedro.io.data_catalog - INFO - Loading data from `testing_data` (MemoryDataSet)...
2021-06-04 17:03:31,868 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:25:52,336 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:25:52,545 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:27:58,269 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:27:58,495 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:34:20,133 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:34:20,344 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:36:32,197 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:36:32,567 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 17:36:59,171 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 17:36:59,172 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
name 'StringIndexer' is not defined
2021-06-04 17:36:59,173 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 17:36:59,174 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:38:22,161 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:38:22,525 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 17:38:48,189 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 17:38:48,442 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
'list' object has no attribute 'fit'
2021-06-04 17:38:48,444 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 17:38:48,445 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:43:48,399 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:43:48,814 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 17:44:14,423 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 17:44:23,844 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
name 'stringindexer_stages' is not defined
2021-06-04 17:44:23,845 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 17:44:23,847 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:49:00,071 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:49:00,163 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:49:50,375 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:49:50,717 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 17:50:16,955 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 17:50:25,672 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
requirement failed: Column stringindexed_OpSys already exists.
2021-06-04 17:50:25,673 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 17:50:25,681 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:51:22,479 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:51:22,838 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 17:52:27,484 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 17:53:12,881 - kedro.io.data_catalog - INFO - Saving data to `transformed_data` (MemoryDataSet)...
2021-06-04 17:53:12,882 - kedro.runner.sequential_runner - INFO - Completed 1 out of 3 tasks
2021-06-04 17:53:12,883 - kedro.io.data_catalog - INFO - Loading data from `transformed_data` (MemoryDataSet)...
2021-06-04 17:53:12,883 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 17:53:12,884 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data]) -> [testing_data,training_data]
2021-06-04 17:53:13,051 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 17:53:13,052 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 17:53:13,052 - kedro.runner.sequential_runner - INFO - Completed 2 out of 3 tasks
2021-06-04 17:53:13,053 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 17:53:13,053 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 17:53:24,809 - kedro_pyspark.pipelines.data_science.nodes - INFO - Training data count: 51487
2021-06-04 17:53:24,812 - kedro.runner.sequential_runner - INFO - Completed 3 out of 3 tasks
2021-06-04 17:53:24,812 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-06-04 17:53:24,812 - kedro.io.data_catalog - INFO - Loading data from `testing_data` (MemoryDataSet)...
2021-06-04 17:53:24,825 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 17:58:52,107 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 17:58:52,169 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:01:53,888 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:01:54,295 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:02:19,971 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:02:19,973 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
'DataFrame' object is not callable
2021-06-04 18:02:19,973 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 18:02:19,975 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:04:19,475 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:04:19,911 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:04:46,276 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:04:46,277 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
name 'col' is not defined
2021-06-04 18:04:46,278 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 18:04:46,280 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:05:35,066 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:05:35,284 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:06:43,066 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:06:43,151 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:08:02,338 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:08:02,722 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:08:28,546 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:08:38,366 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
An error occurred while calling o394.fit.
: org.apache.spark.SparkException: Input column compAboveAvg does not exist.
	at org.apache.spark.ml.feature.StringIndexerBase.$anonfun$validateAndTransformSchema$2(StringIndexer.scala:128)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)
	at scala.collection.mutable.ArrayOps$ofRef.flatMap(ArrayOps.scala:198)
	at org.apache.spark.ml.feature.StringIndexerBase.validateAndTransformSchema(StringIndexer.scala:123)
	at org.apache.spark.ml.feature.StringIndexerBase.validateAndTransformSchema$(StringIndexer.scala:115)
	at org.apache.spark.ml.feature.StringIndexer.validateAndTransformSchema(StringIndexer.scala:145)
	at org.apache.spark.ml.feature.StringIndexer.transformSchema(StringIndexer.scala:251)
	at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:71)
	at org.apache.spark.ml.feature.StringIndexer.fit(StringIndexer.scala:236)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

2021-06-04 18:08:38,366 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 18:08:38,370 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:09:48,580 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:09:48,969 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:10:14,885 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:10:25,343 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
requirement failed: The input column compAboveAvg must be either string type or numeric type, but got BooleanType.
2021-06-04 18:10:25,344 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 18:10:25,354 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:11:46,218 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:11:46,583 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:12:11,943 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:12:26,280 - kedro.io.data_catalog - INFO - Saving data to `transformed_data` (MemoryDataSet)...
2021-06-04 18:12:26,281 - kedro.runner.sequential_runner - INFO - Completed 1 out of 3 tasks
2021-06-04 18:12:26,282 - kedro.io.data_catalog - INFO - Loading data from `transformed_data` (MemoryDataSet)...
2021-06-04 18:12:26,282 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 18:12:26,283 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data]) -> [testing_data,training_data]
2021-06-04 18:12:26,369 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 18:12:26,370 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 18:12:26,371 - kedro.runner.sequential_runner - INFO - Completed 2 out of 3 tasks
2021-06-04 18:12:26,371 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 18:12:26,372 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 18:12:32,594 - kedro.pipeline.node - ERROR - Node `report_count([training_data]) -> None` failed with error: 
An error occurred while calling o438.count.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 6.0 failed 4 times, most recent failure: Lost task 1.3 in stage 6.0 (TID 15, 10.0.55.55, executor 2): org.apache.spark.SparkException: Failed to execute user defined function(StringIndexerModel$$Lambda$2739/134623153: (string) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:395)
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:390)
	... 17 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:2981)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:2980)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2980)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Failed to execute user defined function(StringIndexerModel$$Lambda$2739/134623153: (string) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:395)
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:390)
	... 17 more

2021-06-04 18:12:32,596 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "report_count([training_data]) -> None"
2021-06-04 18:12:32,603 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:15:15,560 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:15:15,922 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:15:42,213 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:15:56,968 - kedro.io.data_catalog - INFO - Saving data to `transformed_data` (MemoryDataSet)...
2021-06-04 18:15:56,969 - kedro.runner.sequential_runner - INFO - Completed 1 out of 3 tasks
2021-06-04 18:15:56,970 - kedro.io.data_catalog - INFO - Loading data from `transformed_data` (MemoryDataSet)...
2021-06-04 18:15:56,970 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 18:15:56,971 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data]) -> [testing_data,training_data]
2021-06-04 18:15:57,041 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 18:15:57,042 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 18:15:57,044 - kedro.runner.sequential_runner - INFO - Completed 2 out of 3 tasks
2021-06-04 18:15:57,044 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 18:15:57,045 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 18:16:03,594 - kedro.pipeline.node - ERROR - Node `report_count([training_data]) -> None` failed with error: 
An error occurred while calling o439.count.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 4 times, most recent failure: Lost task 0.3 in stage 6.0 (TID 15, 10.0.55.57, executor 2): org.apache.spark.SparkException: Failed to execute user defined function(StringIndexerModel$$Lambda$2746/97175999: (string) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:395)
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:390)
	... 17 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2008)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2007)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2007)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:973)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:973)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2239)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2188)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2177)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:775)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2120)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2139)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2164)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)
	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:2981)
	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:2980)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3618)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3616)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2980)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Failed to execute user defined function(StringIndexerModel$$Lambda$2746/97175999: (string) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.sort_addToSorter_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:132)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
Caused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:395)
	at org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:390)
	... 17 more

2021-06-04 18:16:03,597 - kedro.runner.sequential_runner - WARNING - There are 1 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "report_count([training_data]) -> None"
2021-06-04 18:16:03,601 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:19:43,807 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:19:44,184 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:20:09,944 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:20:23,690 - kedro.io.data_catalog - INFO - Saving data to `transformed_data` (MemoryDataSet)...
2021-06-04 18:20:23,692 - kedro.runner.sequential_runner - INFO - Completed 1 out of 3 tasks
2021-06-04 18:20:23,692 - kedro.io.data_catalog - INFO - Loading data from `transformed_data` (MemoryDataSet)...
2021-06-04 18:20:23,693 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 18:20:23,694 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data]) -> [testing_data,training_data]
2021-06-04 18:20:23,750 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 18:20:23,750 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 18:20:23,751 - kedro.runner.sequential_runner - INFO - Completed 2 out of 3 tasks
2021-06-04 18:20:23,751 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 18:20:23,752 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 18:20:34,878 - kedro_pyspark.pipelines.data_science.nodes - INFO - Training data count: 26946
2021-06-04 18:20:34,878 - kedro.runner.sequential_runner - INFO - Completed 3 out of 3 tasks
2021-06-04 18:20:34,879 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-06-04 18:20:34,879 - kedro.io.data_catalog - INFO - Loading data from `testing_data` (MemoryDataSet)...
2021-06-04 18:20:34,885 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:27:04,931 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:27:05,279 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:27:30,065 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:27:30,572 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
can only concatenate list (not "DataFrame") to list
2021-06-04 18:27:30,573 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 18:27:30,574 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:29:09,368 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:29:09,729 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:29:35,482 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:29:35,893 - kedro.pipeline.node - ERROR - Node `transform_features([input_data]) -> [transformed_data]` failed with error: 
can only concatenate list (not "str") to list
2021-06-04 18:29:35,894 - kedro.runner.sequential_runner - WARNING - There are 3 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:

2021-06-04 18:29:35,895 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:30:15,689 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:30:16,041 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:30:42,172 - kedro.pipeline.node - INFO - Running node: transform_features([input_data]) -> [transformed_data]
2021-06-04 18:30:55,795 - kedro.io.data_catalog - INFO - Saving data to `transformed_data` (MemoryDataSet)...
2021-06-04 18:30:55,797 - kedro.runner.sequential_runner - INFO - Completed 1 out of 3 tasks
2021-06-04 18:30:55,797 - kedro.io.data_catalog - INFO - Loading data from `transformed_data` (MemoryDataSet)...
2021-06-04 18:30:55,798 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 18:30:55,799 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data]) -> [testing_data,training_data]
2021-06-04 18:30:55,862 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 18:30:55,863 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 18:30:55,865 - kedro.runner.sequential_runner - INFO - Completed 2 out of 3 tasks
2021-06-04 18:30:55,865 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 18:30:55,866 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 18:31:03,621 - kedro_pyspark.pipelines.data_science.nodes - INFO - Training data count: 26964
2021-06-04 18:31:03,626 - kedro.runner.sequential_runner - INFO - Completed 3 out of 3 tasks
2021-06-04 18:31:03,627 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-06-04 18:31:03,627 - kedro.io.data_catalog - INFO - Loading data from `testing_data` (MemoryDataSet)...
2021-06-04 18:31:03,635 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:41:52,342 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:41:52,427 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:43:19,574 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:43:19,643 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:44:48,586 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:44:49,017 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:45:32,831 - kedro.pipeline.node - INFO - Running node: extract_columns([input_data]) -> [transformed_data1]
2021-06-04 18:45:33,425 - kedro.io.data_catalog - INFO - Saving data to `transformed_data1` (MemoryDataSet)...
2021-06-04 18:45:33,426 - kedro.runner.sequential_runner - INFO - Completed 1 out of 7 tasks
2021-06-04 18:45:33,427 - kedro.io.data_catalog - INFO - Loading data from `transformed_data1` (MemoryDataSet)...
2021-06-04 18:45:33,427 - kedro.pipeline.node - INFO - Running node: apply_string_indexer([transformed_data1]) -> [transformed_data2]
2021-06-04 18:45:33,427 - kedro.pipeline.node - ERROR - Node `apply_string_indexer([transformed_data1]) -> [transformed_data2]` failed with error: 
name 'raw_feature_columns' is not defined
2021-06-04 18:45:33,430 - kedro.runner.sequential_runner - WARNING - There are 6 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_string_indexer([transformed_data1]) -> [transformed_data2],split_data([params:example_test_data_ratio,transformed_data5]) -> [testing_data,training_data]"
2021-06-04 18:45:33,431 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:47:54,300 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:47:54,643 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:48:13,170 - kedro.pipeline.node - INFO - Running node: extract_columns([input_data]) -> [transformed_data1]
2021-06-04 18:48:13,685 - kedro.io.data_catalog - INFO - Saving data to `transformed_data1` (MemoryDataSet)...
2021-06-04 18:48:13,686 - kedro.runner.sequential_runner - INFO - Completed 1 out of 7 tasks
2021-06-04 18:48:13,686 - kedro.io.data_catalog - INFO - Loading data from `transformed_data1` (MemoryDataSet)...
2021-06-04 18:48:13,694 - kedro.pipeline.node - INFO - Running node: apply_string_indexer([transformed_data1]) -> [transformed_data2]
2021-06-04 18:48:20,270 - kedro.io.data_catalog - INFO - Saving data to `transformed_data2` (MemoryDataSet)...
2021-06-04 18:48:20,271 - kedro.runner.sequential_runner - INFO - Completed 2 out of 7 tasks
2021-06-04 18:48:20,271 - kedro.io.data_catalog - INFO - Loading data from `transformed_data2` (MemoryDataSet)...
2021-06-04 18:48:20,272 - kedro.pipeline.node - INFO - Running node: apply_onehot_encoding([transformed_data2]) -> [transformed_data3]
2021-06-04 18:48:20,639 - kedro.io.data_catalog - INFO - Saving data to `transformed_data3` (MemoryDataSet)...
2021-06-04 18:48:20,640 - kedro.runner.sequential_runner - INFO - Completed 3 out of 7 tasks
2021-06-04 18:48:20,641 - kedro.io.data_catalog - INFO - Loading data from `transformed_data3` (MemoryDataSet)...
2021-06-04 18:48:20,642 - kedro.pipeline.node - INFO - Running node: apply_vector_assembler([transformed_data3]) -> [transformed_data4]
2021-06-04 18:48:20,655 - kedro.pipeline.node - ERROR - Node `apply_vector_assembler([transformed_data3]) -> [transformed_data4]` failed with error: 
name 'transformed_data2' is not defined
2021-06-04 18:48:20,657 - kedro.runner.sequential_runner - WARNING - There are 4 nodes that have not run.
You can resume the pipeline run by adding the following argument to your previous command:
  --from-nodes "apply_vector_assembler([transformed_data3]) -> [transformed_data4],split_data([params:example_test_data_ratio,transformed_data5]) -> [testing_data,training_data]"
2021-06-04 18:48:20,659 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-04 18:49:41,986 - root - INFO - ** Kedro project kedro_pyspark
2021-06-04 18:49:42,342 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-04 18:50:00,827 - kedro.pipeline.node - INFO - Running node: extract_columns([input_data]) -> [transformed_data1]
2021-06-04 18:50:01,396 - kedro.io.data_catalog - INFO - Saving data to `transformed_data1` (MemoryDataSet)...
2021-06-04 18:50:01,398 - kedro.runner.sequential_runner - INFO - Completed 1 out of 7 tasks
2021-06-04 18:50:01,398 - kedro.io.data_catalog - INFO - Loading data from `transformed_data1` (MemoryDataSet)...
2021-06-04 18:50:01,405 - kedro.pipeline.node - INFO - Running node: apply_string_indexer([transformed_data1]) -> [transformed_data2]
2021-06-04 18:50:07,429 - kedro.io.data_catalog - INFO - Saving data to `transformed_data2` (MemoryDataSet)...
2021-06-04 18:50:07,430 - kedro.runner.sequential_runner - INFO - Completed 2 out of 7 tasks
2021-06-04 18:50:07,430 - kedro.io.data_catalog - INFO - Loading data from `transformed_data2` (MemoryDataSet)...
2021-06-04 18:50:07,431 - kedro.pipeline.node - INFO - Running node: apply_onehot_encoding([transformed_data2]) -> [transformed_data3]
2021-06-04 18:50:07,905 - kedro.io.data_catalog - INFO - Saving data to `transformed_data3` (MemoryDataSet)...
2021-06-04 18:50:07,906 - kedro.runner.sequential_runner - INFO - Completed 3 out of 7 tasks
2021-06-04 18:50:07,907 - kedro.io.data_catalog - INFO - Loading data from `transformed_data3` (MemoryDataSet)...
2021-06-04 18:50:07,908 - kedro.pipeline.node - INFO - Running node: apply_vector_assembler([transformed_data3]) -> [transformed_data4]
2021-06-04 18:50:08,007 - kedro.io.data_catalog - INFO - Saving data to `transformed_data4` (MemoryDataSet)...
2021-06-04 18:50:08,009 - kedro.runner.sequential_runner - INFO - Completed 4 out of 7 tasks
2021-06-04 18:50:08,010 - kedro.io.data_catalog - INFO - Loading data from `transformed_data4` (MemoryDataSet)...
2021-06-04 18:50:08,011 - kedro.pipeline.node - INFO - Running node: apply_string_indexer_on_label([transformed_data4]) -> [transformed_data5]
2021-06-04 18:50:11,479 - kedro.io.data_catalog - INFO - Saving data to `transformed_data5` (MemoryDataSet)...
2021-06-04 18:50:11,481 - kedro.runner.sequential_runner - INFO - Completed 5 out of 7 tasks
2021-06-04 18:50:11,482 - kedro.io.data_catalog - INFO - Loading data from `transformed_data5` (MemoryDataSet)...
2021-06-04 18:50:11,483 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-04 18:50:11,484 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data5]) -> [testing_data,training_data]
2021-06-04 18:50:11,523 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-04 18:50:11,524 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-04 18:50:11,526 - kedro.runner.sequential_runner - INFO - Completed 6 out of 7 tasks
2021-06-04 18:50:11,526 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-04 18:50:11,527 - kedro.pipeline.node - INFO - Running node: report_count([training_data]) -> None
2021-06-04 18:50:28,226 - kedro_pyspark.pipelines.data_science.nodes - INFO - Training data count: 26944
2021-06-04 18:50:28,227 - kedro.runner.sequential_runner - INFO - Completed 7 out of 7 tasks
2021-06-04 18:50:28,227 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-06-04 18:50:28,227 - kedro.io.data_catalog - INFO - Loading data from `testing_data` (MemoryDataSet)...
2021-06-04 18:50:28,230 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
2021-06-07 12:03:34,743 - root - INFO - ** Kedro project stack-analysis
2021-06-07 12:03:35,236 - kedro.io.data_catalog - INFO - Loading data from `input_data` (SparkDataSet)...
2021-06-07 12:06:55,563 - kedro.pipeline.node - INFO - Running node: extract_columns([input_data]) -> [transformed_data1]
2021-06-07 12:06:56,212 - kedro.io.data_catalog - INFO - Saving data to `transformed_data1` (MemoryDataSet)...
2021-06-07 12:06:56,214 - kedro.runner.sequential_runner - INFO - Completed 1 out of 9 tasks
2021-06-07 12:06:56,214 - kedro.io.data_catalog - INFO - Loading data from `transformed_data1` (MemoryDataSet)...
2021-06-07 12:06:56,215 - kedro.pipeline.node - INFO - Running node: apply_string_indexer([transformed_data1]) -> [transformed_data2]
2021-06-07 12:07:08,379 - kedro.io.data_catalog - INFO - Saving data to `transformed_data2` (MemoryDataSet)...
2021-06-07 12:07:08,381 - kedro.runner.sequential_runner - INFO - Completed 2 out of 9 tasks
2021-06-07 12:07:08,381 - kedro.io.data_catalog - INFO - Loading data from `transformed_data2` (MemoryDataSet)...
2021-06-07 12:07:08,382 - kedro.pipeline.node - INFO - Running node: apply_onehot_encoding([transformed_data2]) -> [transformed_data3]
2021-06-07 12:07:09,010 - kedro.io.data_catalog - INFO - Saving data to `transformed_data3` (MemoryDataSet)...
2021-06-07 12:07:09,012 - kedro.runner.sequential_runner - INFO - Completed 3 out of 9 tasks
2021-06-07 12:07:09,012 - kedro.io.data_catalog - INFO - Loading data from `transformed_data3` (MemoryDataSet)...
2021-06-07 12:07:09,013 - kedro.pipeline.node - INFO - Running node: apply_vector_assembler([transformed_data3]) -> [transformed_data4]
2021-06-07 12:07:09,176 - kedro.io.data_catalog - INFO - Saving data to `transformed_data4` (MemoryDataSet)...
2021-06-07 12:07:09,178 - kedro.runner.sequential_runner - INFO - Completed 4 out of 9 tasks
2021-06-07 12:07:09,179 - kedro.io.data_catalog - INFO - Loading data from `transformed_data4` (MemoryDataSet)...
2021-06-07 12:07:09,180 - kedro.pipeline.node - INFO - Running node: apply_string_indexer_on_label([transformed_data4]) -> [transformed_data5]
2021-06-07 12:07:14,679 - kedro.io.data_catalog - INFO - Saving data to `transformed_data5` (MemoryDataSet)...
2021-06-07 12:07:14,682 - kedro.runner.sequential_runner - INFO - Completed 5 out of 9 tasks
2021-06-07 12:07:14,683 - kedro.io.data_catalog - INFO - Loading data from `transformed_data5` (MemoryDataSet)...
2021-06-07 12:07:14,684 - kedro.io.data_catalog - INFO - Loading data from `params:example_test_data_ratio` (MemoryDataSet)...
2021-06-07 12:07:14,685 - kedro.pipeline.node - INFO - Running node: split_data([params:example_test_data_ratio,transformed_data5]) -> [testing_data,training_data]
2021-06-07 12:07:14,755 - kedro.io.data_catalog - INFO - Saving data to `training_data` (MemoryDataSet)...
2021-06-07 12:07:14,756 - kedro.io.data_catalog - INFO - Saving data to `testing_data` (MemoryDataSet)...
2021-06-07 12:07:14,767 - kedro.runner.sequential_runner - INFO - Completed 6 out of 9 tasks
2021-06-07 12:07:14,768 - kedro.io.data_catalog - INFO - Loading data from `training_data` (MemoryDataSet)...
2021-06-07 12:07:14,770 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...
2021-06-07 12:07:14,771 - kedro.pipeline.node - INFO - Running node: train_model([parameters,training_data]) -> [example_classifier]
2021-06-07 12:07:42,415 - kedro.io.data_catalog - INFO - Saving data to `example_classifier` (MemoryDataSet)...
2021-06-07 12:07:42,417 - kedro.runner.sequential_runner - INFO - Completed 7 out of 9 tasks
2021-06-07 12:07:42,418 - kedro.io.data_catalog - INFO - Loading data from `example_classifier` (MemoryDataSet)...
2021-06-07 12:07:42,418 - kedro.io.data_catalog - INFO - Loading data from `testing_data` (MemoryDataSet)...
2021-06-07 12:07:42,420 - kedro.pipeline.node - INFO - Running node: predict([example_classifier,testing_data]) -> [example_predictions]
2021-06-07 12:07:42,599 - kedro.io.data_catalog - INFO - Saving data to `example_predictions` (MemoryDataSet)...
2021-06-07 12:07:42,603 - kedro.runner.sequential_runner - INFO - Completed 8 out of 9 tasks
2021-06-07 12:07:42,604 - kedro.io.data_catalog - INFO - Loading data from `example_predictions` (MemoryDataSet)...
2021-06-07 12:07:42,605 - kedro.pipeline.node - INFO - Running node: report_accuracy([example_predictions]) -> None
2021-06-07 12:07:48,624 - kedro_pyspark.pipelines.data_science.nodes - INFO - Model accuracy: 77.26%
2021-06-07 12:07:48,626 - kedro.runner.sequential_runner - INFO - Completed 9 out of 9 tasks
2021-06-07 12:07:48,627 - kedro.runner.sequential_runner - INFO - Pipeline execution completed successfully.
2021-06-07 12:07:48,627 - kedro.framework.session.store - INFO - `save()` not implemented for `BaseSessionStore`. Skipping the step.
